<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>Java 集合类 - Wiki | HanSong</title>
    <meta name="keywords" content="wiki, markdown, linux, c, java, python, qemu"/>
    <meta name="description" content="HanSong's personal wiki, recording my little thoughts"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#java">java</a>&nbsp;&#187;&nbsp;Java 集合类
    <span class="updated">Updated&nbsp;
      2016-04-11
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">Java 集合类</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#hashmap">HashMap</a><ul>
<li><a href="#put">put函数的实现</a></li>
<li><a href="#get">get函数的实现</a></li>
<li><a href="#hash">hash函数的实现</a></li>
<li><a href="#resize">resize的实现</a></li>
<li><a href="#hashmap_1">HashMap的装箱空间效率</a></li>
</ul>
</li>
<li><a href="#hashtable-hashmap">Hashtable 与 HashMap 的区别</a></li>
<li><a href="#hashset">HashSet</a></li>
<li><a href="#concurrenthashmap">ConcurrentHashMap</a><ul>
<li><a href="#hashentry">HashEntry</a></li>
<li><a href="#segment">Segment</a></li>
<li><a href="#_1">总结</a></li>
<li><a href="#concurrenthashmap-getclear">ConcurrentHashMap 的 get，clear 方法和迭代器是弱一致性的。</a></li>
</ul>
</li>
<li><a href="#linkedhashmap">LinkedHashMap</a></li>
<li><a href="#arraylist">ArrayList</a></li>
<li><a href="#linkedlist">LinkedList</a></li>
<li><a href="#copyonwritearraylist">CopyOnWriteArrayList</a></li>
<li><a href="#_2">迭代器</a></li>
</ul>
</div>
<h2 id="hashmap">HashMap</h2>
<p>基于 JDK 1.8 分析</p>
<h3 id="put">put函数的实现</h3>
<p>put函数大致的思路为：</p>
<ol>
<li>对key的hashCode()做hash，然后再计算index;</li>
<li>如果没碰撞直接放到bucket里；</li>
<li>如果碰撞了，以链表的形式存在buckets后；</li>
<li>如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树；</li>
<li>如果节点已经存在就替换old value(保证key的唯一性)</li>
<li>如果bucket满了(超过load factor*current capacity)，就要resize。</li>
</ol>
<h3 id="get">get函数的实现</h3>
<ol>
<li>bucket里的第一个节点，直接命中；</li>
<li>如果有冲突，则通过key.equals(k)去查找对应的entry</li>
<li>若为树，则在树中通过key.equals(k)查找，O(logn)；</li>
<li>若为链表，则在链表中通过key.equals(k)查找，O(n)。</li>
</ol>
<h3 id="hash">hash函数的实现</h3>
<p>在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示：</p>
<p><img alt="" src="http://7xjtfr.com1.z0.glb.clouddn.com/293b52fc-d932-11e4-854d-cb47be67949a.png" /></p>
<p>hash函数的实现：高16bit不变，低16bit和高16bit做了一个异或。</p>
<h3 id="resize">resize的实现</h3>
<p>当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。</p>
<p>当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。</p>
<p><img alt="" src="http://7xjtfr.com1.z0.glb.clouddn.com/ceb6e6ac-d93b-11e4-98e7-c5a5a07da8c4.png" /></p>
<p>因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：</p>
<p><img alt="" src="http://7xjtfr.com1.z0.glb.clouddn.com/519be432-d93c-11e4-85bb-dff0a03af9d3.png" /></p>
<p>因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。</p>
<h3 id="hashmap_1">HashMap的装箱空间效率</h3>
<p>在笔试题中，一般“内存”是完全能够使用的，而在现实中HashMap空间效率之低，你却不一定知道。</p>
<p>比如定义了一个 HashMap<Long,Long></p>
<ol>
<li>
<p>Long的装箱</p>
<p>在对象头中，加入额外的指针8Bype，加入8Bype的MarkWord(hashcode与锁信息)，这里就是16Byte。</p>
<p>也就是说，long在装箱后，效率为 8/24 = 1/3</p>
</li>
<li>
<p>Map.Entry的装箱</p>
<p>字段空间: hash(4) + padding(4) ＋ next(8) = 16Byte，这里的padding是字节对齐</p>
<p>对象头: 16Byte，指针+MarkWord</p>
<p>也就是说，维护一个Entry需要32Byte的空间</p>
<div class="hlcode"><pre><span class="k">static</span> <span class="n">class</span> <span class="n">Node</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="o">&gt;</span> <span class="n">implements</span> <span class="n">Map</span><span class="p">.</span><span class="n">Entry</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="o">&gt;</span>
<span class="p">{</span>
    <span class="n">final</span> <span class="kt">int</span> <span class="n">hash</span><span class="p">;</span>
    <span class="n">final</span> <span class="n">K</span> <span class="n">key</span><span class="p">;</span>
    <span class="n">V</span> <span class="n">value</span><span class="p">;</span>
    <span class="n">Node</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="o">&gt;</span> <span class="n">next</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>


</li>
<li>
<p>总效率</p>
<p>8/(24 + 32) = 1/7</p>
</li>
</ol>
<h2 id="hashtable-hashmap">Hashtable 与 HashMap 的区别</h2>
<ol>
<li>
<p>继承的父类不同。</p>
<p>Hashtable 继承自Dictionary类，而HashMap继承自AbstractMap类。但二者都实现了Map接口。</p>
</li>
<li>
<p>线程安全性不同。</p>
<p>Hashtable 中的方法是Synchronize的，而HashMap中的方法在缺省情况下是非Synchronize的。在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用HashMap时就必须要自己增加同步处理。</p>
</li>
<li>
<p>key和value是否允许null值。</p>
<ul>
<li>其中key和value都是对象，并且不能包含重复key，但可以包含重复的value。</li>
<li>Hashtable中，key和value都不允许出现null值。</li>
<li>HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应 的值为null。当get()方法返回null值时，可能是 HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。</li>
<li>HashMap 通过<code>putForNullKey(value)</code>，将 null 键存在<code>table[0]</code>的位置。</li>
</ul>
</li>
<li>
<p>hash值不同</p>
<p>哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。</p>
</li>
<li>
<p>内部实现使用的数组初始化和扩容方式不同。</p>
<ul>
<li>HashTable中hash数组默认大小是11，增加的方式是 old*2+1。</li>
<li>HashMap中hash数组的默认大小是16，而且一定是2的指数。</li>
</ul>
</li>
</ol>
<h2 id="hashset">HashSet</h2>
<ol>
<li>HashSet底层是采用HashMap实现的</li>
<li>调用HashSet的add方法时，实际上是向HashMap中增加了一行(key-value对)，该行的key就是向HashSet增加的那个对象，该行的value就是一个Object类型的常量。</li>
</ol>
<h2 id="concurrenthashmap">ConcurrentHashMap</h2>
<p><em>基于 jdk6 分析</em></p>
<p>ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。</p>
<h3 id="hashentry">HashEntry</h3>
<p>HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。</p>
<p>在 ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。</p>
<h3 id="segment">Segment</h3>
<p>Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。</p>
<p>table 是一个由 HashEntry 对象组成的数组。table 数组的每一个数组成员就是散列映射表的一个桶。</p>
<p>count 变量是一个计数器，它表示每个 Segment 对象管理的 table 数组（若干个 HashEntry 组成的链表）包含的 HashEntry 对象的个数。每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 HashEntry 对象的总数。注意，之所以在每个 Segment 对象中包含一个计数器，而不是在 ConcurrentHashMap 中使用全局的计数器，是为了避免出现“热点域”而影响 ConcurrentHashMap 的并发性。</p>
<h3 id="_1">总结</h3>
<p>ConcurrentHashMap 在默认并发级别会创建包含 16 个 Segment 对象的数组。每个 Segment 的成员对象 table 包含若干个散列表的桶。每个桶是由 HashEntry 链接起来的一个链表。如果键能均匀散列，每个 Segment 大约守护整个散列表中桶总数的 1/16。</p>
<p><img alt="ConcurrentHashMap" src="http://7xjtfr.com1.z0.glb.clouddn.com/ConcurrentHashMap.jpg" /></p>
<p>ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 HashTable 和用同步包装器包装的 HashMap（Collections.synchronizedMap(new HashMap())），ConcurrentHashMap 拥有更高的并发性。在 HashTable 和由同步包装器包装的 HashMap 中，使用一个全局的锁来同步不同线程间的并发访问。同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器。这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。
在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：</p>
<ol>
<li>减小请求同一个锁的频率。</li>
<li>减少持有锁的时间。</li>
</ol>
<p>ConcurrentHashMap 的高并发性主要来自于三个方面：</p>
<ol>
<li>用分离锁实现多个线程间的更深层次的共享访问。</li>
<li>用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。</li>
<li>通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。</li>
</ol>
<p>使用分离锁，减小了请求同一个锁的频率。</p>
<p>通过 HashEntery 对象的不变性及对同一个 Volatile 变量的读 / 写来协调内存可见性，使得读操作大多数时候不需要加锁就能成功获取到需要的值(jdk6 中读到的值为空，则加锁重读，因为可能是其他线程在修改哈希表）。由于散列映射表在实际应用中大多数操作都是成功的读操作，所以 2 和 3 既可以减少请求同一个锁的频率，也可以有效减少持有锁的时间。</p>
<p>通过减小请求同一个锁的频率和尽量减少持有锁的时间 ，使得 ConcurrentHashMap 的并发性相对于 HashTable 和用同步包装器包装的 HashMap 有了质的提高。</p>
<h3 id="concurrenthashmap-getclear">ConcurrentHashMap 的 get，clear 方法和迭代器是<strong>弱一致性</strong>的。</h3>
<ul>
<li>get 方法：没有加锁，如果在 get 的过程中，另一个线程写入或者删除某个元素，get 可能看不到修改后的结果。没有读锁是因为put/remove动作是个原子动作(比如put是一个对数组元素/Entry 指针的赋值操作)，读操作不会看到一个更新动作的中间状态。</li>
<li>clear 方法：因为没有全局的锁，在清除完一个segments之后，正在清理下一个segments的时候，已经清理segments可能又被加入了数据，因此clear返回的时候，ConcurrentHashMap中是可能存在数据的。因此，clear方法是弱一致的。</li>
<li>迭代器：在遍历过程中，如果已经遍历的数组上的内容变化了，迭代器不会抛出ConcurrentModificationException异常。如果未遍历的数组上的内容发生了变化，则有可能反映到迭代过程中。这就是ConcurrentHashMap迭代器弱一致的表现。</li>
</ul>
<blockquote>
<p>在 JDK 6,7,8 中 ConcurrentHashMap 的方法实现略有不同，但总体思想是一样的。</p>
</blockquote>
<h2 id="linkedhashmap">LinkedHashMap</h2>
<p>一个 Map 接口的实现，与 HashMap 不同的是，它维护了一个 Entry 的双向链表，因此其迭代的顺序是可预测的，支持按插入顺序或者访问顺序迭代元素。其 Entry 比 HashMap 的 Entry 多了首尾指针。</p>
<p>扩展HashMap增加双向链表的实现，号称是最占内存的数据结构。支持iterator()时按Entry的插入顺序来排序(但是更新不算， 如果设置accessOrder属性为true，则所有读写访问都算)。</p>
<p>实现上是在Entry上再增加属性before/after指针，插入时把自己加到Header Entry的前面去。如果所有读写访问都要排序，还要把前后Entry的before/after拼接起来以在链表中删除掉自己。</p>
<h2 id="arraylist">ArrayList</h2>
<p>以数组实现。节约空间，但数组有容量限制。超出限制时会增加50%容量，用System.arraycopy()复制到新的数组，因此最好能给出数组大小的预估值。默认第一次插入元素时创建大小为10的数组。</p>
<p>按数组下标访问元素--get(i)/set(i,e) 的性能很高，这是数组的基本优势。</p>
<p>直接在数组末尾加入元素--add(e)的性能也高，但如果按下标插入、删除元素--add(i,e), remove(i), remove(e)，则要用System.arraycopy()来移动部分受影响的元素，性能就变差了，这是基本劣势。</p>
<h2 id="linkedlist">LinkedList</h2>
<p>以双向链表实现。链表无容量限制，但双向链表本身使用了更多空间，也需要额外的链表指针操作。</p>
<p>按下标访问元素--get(i)/set(i,e) 要悲剧的遍历链表将指针移动到位(如果i&gt;数组大小的一半，会从末尾移起)。</p>
<p>插入、删除元素时修改前后节点的指针即可，但还是要遍历部分链表的指针才能移动到下标所指的位置，只有在链表两头的操作--add(), addFirst(),removeLast()或用iterator()上的remove()能省掉指针的移动。</p>
<h2 id="copyonwritearraylist">CopyOnWriteArrayList</h2>
<p>并发优化的ArrayList。用CopyOnWrite策略，在修改时先复制一个快照来修改，改完再让内部指针指向新数组。</p>
<p>因为对快照的修改对读操作来说不可见，所以只有写锁没有读锁，加上复制的昂贵成本，典型的适合读多写少的场景。如果更新频率较高，或数组较大时，还是Collections.synchronizedList(list)，对所有操作用同一把锁来保证线程安全更好。</p>
<p>增加了addIfAbsent(e)方法，会遍历数组来检查元素是否已存在，性能可想像的不会太好。</p>
<h2 id="_2">迭代器</h2>
<p>集合类一般有modCount，表示集合类中的元素被修改了几次(在移除，新加元素时此值都会自增)，而expectedModCount是表示期望的修改次数，在迭代器构造的时候这两个值是相等，如果在遍历过程中这两个值出现了不同步就会抛出ConcurrentModificationException异常。</p>
<p>设置modCount和expectedModCount的目的是为了检测iterator的有效性，检测是否有其它操作对HashMap的结构进行了修改，由于这些操作不是通过当前iterator进行的，因此有可能破坏iterator的有效性。通过iterator执行remove只能删除当前iterator所在的元素，不会让iterator失效。而通过HashMap.remove()实际上可以删除任意元素，这个元素有可能正是iterator内部的next变量已经引用了的元素，造成iterator失效。</p>
<p>HashMap和keySet的remove方法都可以通过传递key参数删除任意的元素，而iterator只能删除当前元素(current)，一旦删除的元素是iterator对象中next所正在引用的，如果没有通过modCount、 expectedModCount的比较实现快速失败抛出异常，下次循环该元素将成为current指向，此时iterator就遍历了一个已移除的过期数据。</p>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2017 HanSong Xiao.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1256629854'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1256629854%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></p>
        <p>Site Generated 2017-05-20 20:29:28</p>
      </span>
    </div>
  </body>
</html>